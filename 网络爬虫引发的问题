
网络爬虫的尺寸
  爬取网页：小规模，数据量小，爬取速度不敏感，Requests库
  爬取网站/系列网站：中规模，数据规模较大，爬取速度敏感，Scrapy库
  爬取全网：大规模，搜索引擎，爬取速度关键


引发问题
  “骚扰”
    为web服务器带来巨大的资源开销
  法律风险
    服务器上的数据有产权归属
    网络爬虫获取数据后牟利将带来法律风险
  泄露隐私
    网络爬虫可能具备突破简单访问控制的能力，获得被保护数据从而泄露个人隐私


网络爬虫的限制
  开源审查：判断User-Agent进行限制
    检查来访HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问
  发布公告：Robots协议
    告知所有爬虫网站的爬取策略，要求爬虫遵守


Robots协议
  Robots Exclusion Standard 网络爬虫排除标准
  作用：网站告知网络爬虫哪些页面可以抓取，哪些不行
  形式：在网站根目录下的robots.txt文件
    # 基本语法，*代表所有，/代表根目录
    User-agent: *
    Disallow: /

  遵守方式
    网络爬虫：自动或人工识别robots.txt，再进行内容爬取
    约束性：Robots协议是建议但非约束性，网络爬虫可以不遵守，但存在法律风险
    类人行为可不参考Robots协议
    
  理解
    爬取网页：访问量很小，可以遵守；访问量较大，建议遵守
    爬取网站/系列网站：非商业且偶尔：建议遵守；商业利益：必须遵守
    爬取全网：必须遵守

